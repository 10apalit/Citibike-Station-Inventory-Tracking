{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb098273-5119-4b01-b718-c58b9c7f9cfd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Prophet\n",
    "<a href=\"https://facebook.github.io/prophet/\" target=\"_blank\">Facebook's Prophet</a> is widely considered the easiest way to forecast because it generally does all the heavy lifting for the user. Let's take a look at how Prophet works with a monthly sales revenue dataset.\n",
    "\n",
    "References:\n",
    "- <a href=\"https://cran.r-project.org/web/packages/prophet/prophet.pdf\" target=\"_blank\">Prophet Librady Docs (R)</a>\n",
    "\n",
    "## Additional Prophet Features for the Final Project\n",
    "- [Diagnostics](http://facebook.github.io/prophet/docs/diagnostics.html) will be helpful information to understand hyperparams to be tuned using an appropriate parallelization mechanism like threads\n",
    "```\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "```\n",
    "\n",
    "- [Regressors](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html) will be helpful for things like weather affect on forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c3d3f4-fddf-4a53-a8ce-07d39845c9f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet, serialize\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import itertools\n",
    "\n",
    "\n",
    "SOURCE_DATA = (\n",
    "    \"https://raw.githubusercontent.com/facebook/prophet/master/examples/example_retail_sales.csv\"\n",
    ")\n",
    "ARTIFACT_PATH = \"Gxx-model\"\n",
    "np.random.seed(12345)\n",
    "\n",
    "## Helper routine to extract the parameters that were used to train a specific instance of the model\n",
    "def extract_params(pr_model):\n",
    "    return {attr: getattr(pr_model, attr) for attr in serialize.SIMPLE_ATTRIBUTES}\n",
    "\n",
    "\n",
    "sales_data = pd.read_csv(SOURCE_DATA)\n",
    "print(sales_data.head())\n",
    "print(sales_data.shape)\n",
    "print(f\"{len(sales_data)} months of sales data loaded ({round(len(sales_data)/12,2)} years)\")\n",
    "\n",
    "# Visualize data using seaborn\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.lineplot(x=sales_data['ds'], y=sales_data['y'])\n",
    "plt.legend(['Sales Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ec0f82-ecfc-4e44-a132-1ddde8327fc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef37bd97-1a64-4a56-b05b-4f5d90a772f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('select * from silver_station_status_dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "774cc577-71be-48c1-983e-193e2580b107",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ab2c35-eb50-4594-9cb4-eaec56c68cfe",
     "showTitle": true,
     "title": "Create a Baseline Model and record the performance"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('use database g04_db')#--------------------------------------------#\n",
    "# Baseline Model Using Default Hyperparameters\n",
    "# - Horizon - period over which we forecast\n",
    "# - Initial - amount of initial training data\n",
    "# - Period - time between cutoffs (usually H/2)\n",
    "# - Cutoff - beginning of the Horizon forecast period\n",
    "#--------------------------------------------#\n",
    "\n",
    "# Initiate the model\n",
    "baseline_model = Prophet()\n",
    "print(sales_data.shape)\n",
    "# Fit the model on the training dataset\n",
    "baseline_model.fit(sales_data)\n",
    "\n",
    "# Cross validation\n",
    "baseline_model_cv = cross_validation(model=baseline_model, initial='710 days', period='180 days', horizon = '365 days', parallel=\"threads\")\n",
    "baseline_model_cv.head()\n",
    "\n",
    "# Model performance metrics\n",
    "baseline_model_p = performance_metrics(baseline_model_cv, rolling_window=1)\n",
    "baseline_model_p.head()\n",
    "\n",
    "# Get the performance value\n",
    "print(f\"MAPE of baseline model: {baseline_model_p['mape'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "058ee334-c779-49ce-a921-8f63bab4af2e",
     "showTitle": true,
     "title": "Perform a hyperparameter search and record results in mlflow tracking db"
    }
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "# Automatic Hyperparameter Tuning\n",
    "#--------------------------------------------#\n",
    "\n",
    "# Set up parameter grid\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001],  # , 0.05, 0.08, 0.5\n",
    "    'seasonality_prior_scale': [0.01],  # , 1, 5, 10, 12\n",
    "    'seasonality_mode': ['additive', 'multiplicative']\n",
    "}\n",
    "  \n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "print(f\"Total training runs {len(all_params)}\")\n",
    "\n",
    "# Create a list to store MAPE values for each combination\n",
    "mapes = [] \n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    with mlflow.start_run(): \n",
    "        # Fit a model using one parameter combination + holidays\n",
    "        m = Prophet(**params) \n",
    "        holidays = pd.DataFrame({\"ds\": [], \"holiday\": []})\n",
    "        m.add_country_holidays(country_name='US')\n",
    "        m.fit(sales_data) \n",
    "\n",
    "        # Cross-validation\n",
    "        df_cv = cross_validation(model=m, initial='710 days', period='180 days', horizon = '365 days', parallel=\"threads\")\n",
    "        # Model performance\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "\n",
    "        metric_keys = [\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "        metrics = {k: df_p[k].mean() for k in metric_keys}\n",
    "        params = extract_params(m)\n",
    "\n",
    "        print(f\"Logged Metrics: \\n{json.dumps(metrics, indent=2)}\")\n",
    "        print(f\"Logged Params: \\n{json.dumps(params, indent=2)}\")\n",
    "\n",
    "        mlflow.prophet.log_model(m, artifact_path=ARTIFACT_PATH)\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        model_uri = mlflow.get_artifact_uri(ARTIFACT_PATH)\n",
    "        print(f\"Model artifact logged to: {model_uri}\")\n",
    "\n",
    "        # Save model performance metrics for this combination of hyper parameters\n",
    "        mapes.append((df_p['mape'].values[0],model_uri))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab9c953f-5f3f-4045-ad60-00c1176a3833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tuning results\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['mape'] = list(zip(*mapes))[0]\n",
    "tuning_results['model']= list(zip(*mapes))[1]\n",
    "\n",
    "best_params = dict(tuning_results.iloc[tuning_results[['mape']].idxmin().values[0]])\n",
    "\n",
    "print(json.dumps(best_params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e74b93-ebf9-40ec-83ee-12eb5a677810",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.prophet.load_model(best_params['model'])\n",
    "\n",
    "forecast = loaded_model.predict(loaded_model.make_future_dataframe(36, freq=\"m\"))\n",
    "\n",
    "print(f\"forecast:\\n${forecast.tail(40)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84befbb9-5df6-409b-8b7b-1a46ab597357",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prophet_plot = loaded_model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d69fbe93-1efb-49a9-88e1-213134255343",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prophet_plot2 = loaded_model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c57c645-00fd-4058-bdc4-5fda2e7dff5b",
     "showTitle": true,
     "title": "Create a residual plot by joining training data with forecast"
    }
   },
   "outputs": [],
   "source": [
    "results=forecast[['ds','yhat']].join(sales_data, lsuffix='_caller', rsuffix='_other')\n",
    "results['residual'] = results['yhat'] - results['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33266037-5308-4c20-9741-bf26f7a5cb97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#plot the residuals\n",
    "fig = px.scatter(\n",
    "    results, x='yhat', y='residual',\n",
    "    marginal_y='violin',\n",
    "    trendline='ols',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d260bd2-2395-40ae-9c5a-d59eb056469b",
     "showTitle": true,
     "title": "Register the best model and move it into staging"
    }
   },
   "outputs": [],
   "source": [
    "model_details = mlflow.register_model(model_uri=best_params['model'], name=ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbf88dd0-2218-4edd-871f-1fe07a93a590",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ceb2fb-b347-4c77-b68b-3bdc61a3034e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.transition_model_version_stage(\n",
    "\n",
    "  name=model_details.name,\n",
    "\n",
    "  version=model_details.version,\n",
    "\n",
    "  stage='Staging',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a657073-8fc7-4b12-a20c-c871ba85e99a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_version_details = client.get_model_version(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    ")\n",
    "print(\"The current model stage is: '{stage}'\".format(stage=model_version_details.current_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb97db1c-e9f3-40b9-bd88-cc6d4318a287",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "latest_version_info = client.get_latest_versions(ARTIFACT_PATH, stages=[\"Staging\"])\n",
    "\n",
    "latest_staging_version = latest_version_info[0].version\n",
    "\n",
    "print(\"The latest staging version of the model '%s' is '%s'.\" % (ARTIFACT_PATH, latest_staging_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7df9054-6dca-4f33-8c96-7d0404772438",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_staging_uri = \"models:/{model_name}/staging\".format(model_name=ARTIFACT_PATH)\n",
    "\n",
    "print(\"Loading registered model version from URI: '{model_uri}'\".format(model_uri=model_staging_uri))\n",
    "\n",
    "model_staging = mlflow.prophet.load_model(model_staging_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b73a92d8-ce25-4d34-80c9-91980a2ae098",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_staging.plot(model_staging.predict(model_staging.make_future_dataframe(36, freq=\"m\")))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prophet Forecasting",
   "notebookOrigID": 1260983850962608,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
